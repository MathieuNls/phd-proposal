%!TEX root = research_proposal.tex

\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{Introduction}

% Section that introduces the field and motivates the necessity to conduct studies in this field
Software maintenance activities such as debugging, refactoring, and feature enhancement are known to be challenging and costly \cite{Pressman2005}.
Studies have shown that the cost of software maintenance can reach up to 70\% of the overall cost of the software development life cycle \cite{HealthSocial2002}.
Much of this is attributable to several factors including the increase in software complexity, the lack of traceability between the various artefacts of the software development process, the lack of proper documentation,  and the unavailability of the original developers of the systems.

Research in software maintenance has evolved over the years to include areas like mining bug repositories, bug analysis, prevention and reproduction. The ultimate goal is to develop techniques and tools to help software developers detect, correct, and prevent bugs in an effective and efficient manner. Several tools have developed

Despite the recent advances in the field,  the literature shows that many existing software maintenance tools have yet to be adopted by industry \cite{Lewis2013,Foss2015,Layman2007,Ayewah2007,Ayewah2008,Johnson2013,Norman2013, Hovemeyer2004, Lopez2011}. This is caused by the following factors:
\begin{itemize}
	\item Work flow integration: Most of these tools (\cite{Rutar,Hovemeyer2004a,Kim2006a,Ayewah2008b, Findbugs2015,Moha2010,Palma,Nayrolles2013d,Nayrolles,Nayrolles2013a, Nayrolles2015a} are some noticeable examples) are not integrated well with the work flow of software developers (i.e. coding, testing, debugging, committing).
	Indeed, developers are constantly switching from one workspace to another for different tasks (i.e. feature location with a command line tool, development and testing  code with an IDE, development and testing front end code with another IDE and a browser,...) \cite{Gonzalez2004,Ko2006a,Layman2009a,Murphy-Hill2012a} and these tools further interrupt this already fragmented process 	\cite{Robertson2004,Robertson2006,Beckwith2006}.
	Furthermore, these tools do not follow developers across workspace; they are bound to one workspace (i.e. an Eclipse plugin \cite{Verbaere2007}).
	Hence, developers have to download, install and understand many tools to achieve any given task.

	\item Actionable outcome: The outcome of these tools tend do not lead to actionable items.
	Most of these tools return several results that are hard to interpret.
	Take for example, FindBugs \cite{Hovemeyer2004}, a well-known bug detection tool.
	This tool detects 424 bug signatures and reports them using abbreviated code such as {\tt CO\_COMPARETO\_INCORRECT \_FLOATING}.
	Using this code, developers can browse FindBug's dictionary and find the following definition {\it ``This method compares double or float values using pattern like this: $val1 > val2~?~1 : val1 < val2~?~-1 : 0$. This pattern works incorrectly for -0.0 and NaN [...]''}\cite{Findbugs2015}.
	While the detection of this bug pattern and the definition are accurate, there is no actionable actions for developers to adjust their code accordingly.
	Moreover, these tools' output is so verbose that developers tend to simply ignore them \cite{Arai2014, Kim2007b, Kim2007c} or use, in addition, filtering and ranking tools \cite{Ayewah2010, Shen2011}.

	\item Leverage of historical data: These tools do not leverage a large body of knowledge that already exist in open source systems.
	In API usage recommendation, researchers built tools that leverage open-source data of multiple projects to recommend how to use a given API \cite{Rahman2013,Kim2013d,Montandon2013}.
	For defect prevention, however, the state-of-the-art approaches consist in adapting statistical models built for a project to another \cite{Lo2013,Nam2013}.
	As argued by Lewis {\it et al.} \cite{Lewis2013} and Johnson {\it et al.} \cite{Johnson2013}, approaches based solely on statistical models are perceived as black boxes by developers.
	Consequently, they are less likely to trust the output of the tool and therefore, use it.
\end{itemize}

In this thesis, we propose to address the above-mentioned issues by focusing on developing techniques and tools that help software developers at commit-time.
In developers's workflow, the commit marks the end of a given task or subtasks as the developer is ready to version the source code.
Consequently, actionning historical data, real-world examples in a clear and concise way at commit-time will prevent additional interuptions.
Moreover, any real-world project uses a version control system and distilling advices at during the versionning operations, such as commit, will provide an unique experience for developers as they will be able to use the same tool across their different workspaces and projects.

More precisely, we propose the following contributions:
\begin{itemize}
	\item An aggregated bug repository system.
	\item A new bug classification based on the locations of the corrections.
	\item A clone prevention technique at commit-time.
	\item A bug prevention technique at commit-time
	\item A bug reproduction technique based on directed model checking and crash traces
\end{itemize}

% Section that motivates the need for BUMPER and the bug taxonomy
When facing a new bug, one might want to leverage decades of open source software history to find a suitable solution.
The chances are that a similar bug has already been fixed somewhere  in  another  open  source  project.
The  problem  is that each open source project hosts its data in a different data repository,  using  different  bug  tracking  and  version  control systems. Moreover,  these  systems  have  different  interfaces to  access  data.
The  data  is  not  represented  in  a  uniform way  either.
This  is  further  complicated  by  the  fact  that  bug tracking tools and version control systems are not necessarily connected. The  former  follows  the  life  of  the  bug,  while  the latter  manages  the  fixes.
As  a  result,  one  would  have  to search the version control system repository to find candidate solutions.
Moreover,  developers  mainly  use  classical  search  engines that  index  specialized  sites  such  as  StackOverflow.
These sites  are  organized  in  the  form  of  question-response  where a developer submits a problem and receives answers from the community. While the answers are often accurate and precise, they do not leverage the history of open source software that has been shown to provide useful insights to help with many maintenance activities such as bug fixing \cite{Saha2014}, bug reproduction \cite{Nayrolles2015}, fault analysis \cite{Nessa2008}, etc.


% Section that motivates the need to study the problem of bug reproduction
When a system crashes, software developers need to reproduce the crash (usually in a lab environment) so as to provide corrective measures. A survey conducted with the developers of major open source software systems such as Apache, Mozilla and Eclipse revealed that one of the most valuable piece of information that can help locate and fix the cause of a crash is the one that can help reproduce it \cite{Bettenburg2008}. Crash reproduction is  an expensive task because the data provided by end users is often scarce \cite{Artzi2008,Jin2012,Chen2013}. It is therefore important to invest in techniques and tools for automatic bug reproduction to ease the maintenance process and accelerate the rate of bug fixes and patches.
Existing techniques can be divided into two categories: (a) On-field record and in-house replay \cite{Steven2000,Narayanasamy2005,Artzi2008,Roehm2015}, and (b) In-house crash explanation \cite{Jin2012,Jin2013,Zuddas2014,Chen2013a,Nayrolles2015}.


The first category relies on instrumenting the system in order to capture objects and other system components at run-time.
When a faulty behaviour occurs in the field, the stored objects as well as the entire heap are sent to the developers along with the faulty methods to reproduce the crash.
These techniques tend to be simple to implement and yield good results, but they suffer from two main limitations.
First, code instrumentation comes with a non-negligible overhead on the system.
The second limitation is that the collected objects may contain sensitive information causing customer privacy issues.
The second category is composed of tools leveraging proprietary data in order to provide hints on potential causes.
While these techniques are efficient in improving our comprehension of the bugs, they are not designed with the purpose of reproducing them.


% Section that motivates the need for PRECINT (for preventing bug and clone insertion)
Code clones appear when developers reuse code with little to no modification to the original code.
Studies have shown that clones can account for about 7\% to 50\% of code in a given software system \cite{Baker, StephaneDucasse}. Developers often reuse code (and create clones) in their software on purpose \cite{Kim2005}.
Nevertheless, clones are considered a bad practice in software development since they can introduce new bugs in the code \cite{Kapser2006,Juergens2009,Li2006}. If a bug is discovered in one segment of the code that has been copied and pasted several times, then the developers will have to remember the places where this segment has been reused in order to fix the bug in each place. In the last two decades, there have been many studies and tools that aim at detecting clones.
They can be grouped into three categories. Although these techniques and tools have been shown to be useful in detecting clones, they operate in an off-line fashion (i.e., after the clones have been inserted). Software developers might be reluctant to use these tools on a day-today basis (i.e., as part of the continuous development process), unless they are involved in a major refactoring effort. This problem is somehow similar to the problem of adopting bug identification tools. Johnson et al. \cite{Johnson2013} showed that these tools are challenging to use because they do not integrate well with the day-to-day workflow of a developer. Also they output a large amount of data when applied to the entire system, making it hard to understand and analyse their results.

% Section that motivates the need for a taxonomy of bugs based on the location of the corrections.
There have been several studies (e.g., \cite{Weiß2007, Zhang2013}) that study of the factors that influence the bug fixing time.
These studies   empirically investigate the relationship between bug report attributes (description, severity, etc.) and the fixing time. Other studies take bug analysis to another level by investigating techniques and tools for bug prediction and reproduction (e.g., \cite{Chen2013, Kim2007a, Nayrolles2015}). These studies, however, treat all bugs as the same.
For example, a bug that requires only one fix is analysed the same way as a bug that necessitates multiple fixes.
Similarly, if multiple bugs are fixed by modifying the exact same locations in the code, then we should investigate how these bugs are related in order to predict them in the future. Note here that we do not refer to duplicate bugs. Duplicate bugs are marked as duplicate (and not fixed) and only the master bug is fixed.

As a motivating example, consider Bugs \#AMQ-5066 and \#AMQ-5092 from the Apache Software Foundation bug report management system (used to build one of the datasets in this paper).
Bug \#AMQ-5066 was reported on February 19, 2014 and solved with a patch provided by the reporter.
The solution involves a relatively complex patch that modifies {\tt MQTTProtocolConverter.java}, {\tt MQTTSubscription.java} and {\tt MQTTTest.java} files.
The description of the bug is as follows:
\\ \\
{\it When a client sends a SUBSCRIBE message with the same Topic/Filter as a previous SUBSCRIBE message but a different QoS, the Server MUST discard the older subscription, and resend all retained messages limited to the new Subscription QoS.}
\\ \\
A few months later, another bug, Bug \#AMQ-5092 was reported:
\\ \\
{\it MQTT protocol converters does not correctly generate unique packet ids for retained and non-retained publish messages sent to clients.
[...] Although retained messages published on creation of client subscriptions are copies of retained messages, they must carry a unique packet id when dispatched to clients.
ActiveMQ re-uses the retained message's packet id, which makes it difficult to  acknowledge these messages when wild card topics are used.
ActiveMQ also sends the same non-retained message multiple times for every matching subscription for overlapping subscriptions.
These messages also re-use the publisher's message id as the packet id, which breaks client acknowledgement.}
\\ \\
This bug was assigned and fixed by a different person than the one who fixed bug \#AMQ-5066.
The fix consists of modifying slightly the same lines of the code in the exact files used to fix Bug \#AMQ-5066.
In fact, Bug \#5092 could have been avoided altogether if the first developer provided a more comprehensive fix to \#AMQ-5066 (a task that is easier said than done).
These two bugs are not duplicates since, according to their description, they deal with different types of problems and yet they can be fixed by providing a similar patch.
In other words, the failures are different while the root causes (faults in the code) are more or less the same.
From the bug handling perspective, if we can develop a way to detect such related bug reports during triaging then we can achieve considerable time saving in the way bug reports are processed, for example, by assigning them to the same developers.
We also conjecture that detecting such related bugs can help with other tasks such as bug reproduction.
We can  reuse the reproduction of an already fixed bug to reproduce an incoming and related bug.

\section{Research Contributions\label{sec:objective-thesis}}

In this section, we present our research contributions that are listed here and developed in more detail in the next subsections.

\begin{itemize}
	\item An aggregate bug  repository for  developers  and  Researchers.
	\item A bug reproduction technique based on a combination of crash traces and model checking.
	\item An incremental approach for preventing clone insertion at commit time
	\item A new taxonomy of bugs based on the location of the corrections --- an empirical Study
\end{itemize}

\subsection{An aggregate bug  repository for  developers  and  researchers}
We introduce BUMPER (BUg Metarepository for  dEvelopers  and  Researchers),  a  web-based  infrastructure
that  can  be  used  by  software  developers  and  researchers  to access  data  from  diverse  repositories  using  natural  language queries in a transparent manner, regardless of where the data was originally created and hosted.
The  idea  behind  BUMPER  is  that  it  can  connect  to  any bug  tracking  and  version  control  systems  and  download  the data  into  a  single  database.
We  created  a  common  schema that represents data, stored in various bug tracking and version control systems.
BUMPER uses a web-based interface to allow users to search the aggregated database by expressing queries through a single point of access.
This way, users can focus on the analysis itself and not on the way the data is represented or located.
BUMPER supports many features including: (1) the ability to use multiple bug tracking and control version systems, (2) the  ability  to  search  very  efficiently  large  data  repositories using both natural language and a specialized query language, (3)  the  mapping  between  the  bug  reports  and  the  fixes,  and (4)  the  ability  to  export  the  search  results  in  Json,  CSV  and XML formats.

\subsection{A bug reproduction technique based on a combination of crash traces and model checking}

In this work, we propose an approach, called JCHARMING (Java CrasH Automatic Reproduction by directed Model checkING) that uses a combination of crash traces and model checking to automatically reproduce bugs that caused field failures.
Unlike existing techniques, JCHARMING does not require instrumentation of the code.
It does not need access to the content of the heap either.
Instead, JCHARMING uses a list of functions output when an uncaught exception in Java occurs (i.e., the crash trace) to guide a model checking engine to uncover the statements that caused the crash.

\subsection{An incremental approach for preventing bug and clone insertion at commit time}
In this research, we present PRECINCT (PREventing Clones INsertion at Commit Time) that focuses on preventing the
insertion of clones at commit time, i.e., before they reach the central code repository.
PRECINCT is an online clone
detection technique that relies on the use of pre-commit hooks capabilities of modern source code version control systems.
A pre-commit hook is a process that one can implement to receive the latest modification to the source code done by a given developer just before the code reaches the central repository.
PRECINCT intercepts this modification and analyses its content to see whether a suspicious clone has been introduced
or not.
A flag is raised if a code fragment is suspected to be a clone of an existing code segment.
In fact, PRECINCT, itself, can be seen as a pre-commit hook that detects clones that might have been inserted in the latest changes with regard to the rest of the source code.
This said, only a fraction of the
code is analysed, making PRECINCT efficient compared to leading clone detection techniques such as NICAD (Accurate Detection of Near-miss Intentional Clones) \cite{Roy2008,Cordy2011}.
Moreover, the detected clones are presented using a classical ‘diff’ output that developers are familiar with.
PRECINCT is also well
integrated with the workflow of the developers since it is used in conjunction with a source code version control systems such as Git.

\subsection{A new taxonomy of bugs based on the location of the correction --- an empirical Study}

We investigate the relationship between bugs by examining their locations of the fixes.
By a fix, we mean a modification (adding or deleting lines of code) to an exiting file that is used to solve the bug.We argue that bugs can be classified into four types:
A bug of Type 1 refers to a bug being fixed in one single location (i.e., one file), while Type 2 refers to bugs being fixed in more than one location.
Type 3 refers to multiple bugs that are fixed in the exact same location.
Type 4 is an extension of Type 3, where multiple bugs are resolved by modifying the same set of locations.
Note that Type 3 and Type 4 bugs are not duplicates, they may occur when different features of the system fail due to the same root causes (faults).
We conjecture that knowing the proportions of each type of bugs in a system may provide insights into the quality of the system.
Knowing, for example, that in a given system the proportion of Type 2 and 4 bugs is high may be an indication of poor system quality since many fixes are needed to address these bugs.
In addition, the existence of a high number of Types 3 and 4 bugs calls for techniques that can effectively find bug reports related to an incoming bug during triaging.
This is similar to the many studies that exist on detection of duplicates (e.g., \cite{Runeson2007, Sun2010,Nguyen2012}), except that we are not looking for duplicates but for related bugs (bugs that are due to failures of different features of the system, caused by the same faults).

\section{Outline\label{sec:outline}}

The remaining chapters of this proposal are:

\begin{itemize}
	\item Chapter \ref{chap:relwork} - {\it Background \& Related work}.
	In this chapter, we present the major studies related to our research field, namely, crash reproduction, aggregating bug repositories for mining purposes, and clone detection.

	\item Chapter \ref{chap:bumper} - {\it An Aggregate Bug Repository for Developers and Researchers}.
	In this chapter, we present {\tt BUMPER} (BUg Metarepository for  dEvelopers  and  Researchers), our bug meta-repository. {\tt BUMPER} acts as our data source for the different contributions.

	\item Chapter \ref{chap:jcharming} - {\it JCHARMING: Java CrasH Automatic Reproduction by directed Model checkING}.
	In this chapter we discuss the components of JCHARMING, the bug reproduction approach we propose.

	\item Chapter \ref{chap:clone-detection-pragmatic} {\it Preventing Clone Insertion}. This chapter describes one approach to     prevent the insertion of clones at commit time.

	\item Chapter \ref{chap:bianca} {\it Preventing Bug Insertion Using Clone Detection}. In this chapter, we present an approach named {\tt BIANCA} (Bug Insertion ANticipation by Clone Analysis at merge time) which uses clone detection to prevent bug insertion.

	\item Chapter \ref{chap:plan} {\it Remaining Work to Complete the Thesis} presents  the remaining work and a publication plan.
\end{itemize}
