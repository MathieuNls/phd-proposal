%!TEX root = research_proposal.tex

\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{Introduction}

/% Section that introduces the field and motivates the necessity to conduct studies in this field
Software maintenance activities such as debugging are known to be challenging and costly\cite{Pressman2005}. Studies have shown that the cost of software maintenance can reach up to 70\% of the overall cost of the software development life cycle \cite{HealthSocial2002}. Much of this is attributable to several factors including the increase in software complexity, the lack of traceability between the various phases of the software development process, the lack of proper documentation,  and the unavailability of the original developers of the systems. 

Research in software maintenance has evolved over the years to include areas like mining bug repositories, bug analysis, prevention and reproduction. The ultimate goal is to investigate techniques and tools to help software developers detect, correct, and prevent bugs in an effective and efficient manner. 

Despite the recent the advances in the field, our survey of the literature shows that several research challenges remain unaddressed. This may explain, in our opinion, the lack of adoption of existing research tools by industry [REF]. [WAHAB: You can put the Google paper here]. 

We focus in this research on the following practical issues. We discuss our proposed solutions in the next section.
- The lack of effective bug reproduction techniques
- The lack of homogeneity of existing bug repositories
- The lack of on-line (and usable) clone insertion prevention techniques
- The need for a new bug classification based on the locations of the corrections.

/% Section that motivates the need to study the problem of bug reproduction
When a system crashes, software developers need to reproduce the crash (usually in a lab environment) in order to provide corrective measures.  A survey conducted with developers of major open source software systems such as Apache, Mozilla and Eclipse reveals that one of the most valuable piece of information that can help locate and fix the cause of a crash is the one that can help reproduce it [REF]. Crash reproduction is  an expensive task because the data provided by end users is often scarce [REF]. It is therefore important to invest in techniques and tools for automatic bug reproduction to ease the maintenance process and accelerate the rate of bug fixes and patches. Existing techniques can be divided into two categories: (a) On-field record and in-house replay [2]–[4], and (b) In-house crash explanation [5], [6]. The first category relies on instrumenting the system in order to capture objects and other system components at run-time. When a faulty behavior occurs in the field, the stored objects as well as the entire heap are sent to the developers along with the faulty methods to reproduce the crash. These techniques tend to be simple to implement and yield good results, but they suffer from two main limitations. First, code instrumentation comes with a non-negligible overhead on the system. The second limitation is that the collected objects may contain sensitive information causing customer privacy issues. The second category is composed of tools leveraging proprietary data in order to provide hints on potential causes. While these techniques are efficient in improving our comprehension of the bugs, they are not designed with the purpose of reproducing them. 

/% Section that motivates the need for BUMPER and the bug taxonomy
When facing a new bug, one might want to leverage decades of open source software history to find a suitable solution. The
chances are that a similar bug or crash has already been fixed somewhere  in  another  open  source  project.  The  problem  is
that each open source project hosts its data in a different data repository,  using  different  bug  tracking  and  version  control systems.  Moreover,  these  systems  have  different  interfaces to  access  data.  The  data  is  not  represented  in  a  uniform way  either.  This  is  further  complicated  by  the  fact  that  bug tracking tools and version control systems are not necessarily connected.  The  former  follows  the  life  of  the  bug,  while  the latter  manages  the  fixes.  As  a  result,  one  would  have  to search the version control system repository to find candidate
solutions. Moreover,  developers  mainly  use  classical  search  engines that  index  specialized  sites  such  as  StackOverflow. These sites  are  organized  in  the  form  of  question-response  where a developer submits a problem and receives answers from the community. While the answers are often accurate and precise, they do not leverage the history of open source software that has been shown to provide useful insights to help with many maintenance activities such as bug fixing [2], bug reproduction [3], fault analysis [4], etc.

/% Section that motivates the need for PRECINT (for preventing bug and clone insertion)
Code clones appear when developers reuse code with little to no modification to the original code. Studies have shown
that clones can account for about 7\% to 50\% of code in a given software system [1], [2]. Developers often reuse code (and
create clones) in their software on purpose [3]. Nevertheless, clones are considered a bad practice in software development
since they can introduce new bugs in the code [4]–[6]. If a bug is discovered in one segment of the code that has been
copied and pasted several times, then the developers will have to remember the places where this segment has been reused
in order to fix the bug in each place. In the last two decades, there have been many studies and tools that aim at detecting clones. They can be grouped into three categories. Although these techniques and tools have been shown to
be useful in detecting clones, they operate in an off-line fashion (i.e., after the clones have been inserted). Software
developers might be reluctant to use these tools on a day-today basis (i.e., as part of the continuous development process),
unless they are involved in a major refactoring effort. This problem is somehow similar to the problem of adopting bug
identification tools. Johnson et al. [18] showed that these tools are challenging to use because they do not integrate well with
the day-to-day workflow of a developer. Also they output a large amount of data when applied to the entire system, making
it hard to understand and analyse their results.


/% Section that motivates the need for a taxonomy of bugs based on the location of the corrections.
There have been several studies (e.g., [1], [7]) that study of the factors that influence the bug fixing time. These studies   empirically investigate the relationship between bug report attributes (description, severity, etc.) and the fixing time.  Other studies take bug analysis to another level by investigating techniques and tools for bug prediction and reproduction (e.g., [3], [8], [9]).  These studies, however, treat all bugs as the same. For example, a bug that requires only one fix is analyzed the same way as a bug that necessitates multiple fixes. Similarly, if multiple bugs are fixed by modifying the exact same locations in the code, then we should investigate how these bugs are related in order to predict them in the future. Note here that we do not refer to duplicate bugs. Duplicate bugs are marked as duplicate (and not fixed) and only the master bug is fixed.
As a motivating example, consider Bugs #AMQ-5066 and #AMQ-5092 from the Apache Software Foundation bug report management system (used to build one of the datasets in this paper). Bug #AMQ-5066 was reported on February 19, 2014 and solved with a patch provided by the reporter. The solution involves a relatively complex patch that modifies MQTTProtocolConverter.java, MQTTSubscription.java and MQTTTest.java files. The description of the bug is as follows:

“When a client sends a SUBSCRIBE message with the same Topic/Filter as a previous SUBSCRIBE message but a different QoS, the Server MUST discard the older subscription, and resend all retained messages limited to the new Subscription QoS.”

A few months later, another bug, Bug #AMQ-5092 was reported: 

“MQTT protocol converters does not correctly generate unique packet ids for retained and non-retained publish messages sent to clients. […] Although retained messages published on creation of client subscriptions are copies of retained messages, they must carry a unique packet id when dispatched to clients. ActiveMQ re-uses the retained message's packet id, which makes it difficult to  acknowledge these messages when wildcard topics are used.
ActiveMQ also sends the same non-retained message multiple times for every matching subscription for overlapping subscriptions. These messages also re-use the publisher's message id as the packet id, which breaks client acknowledgment.”

This bug was assigned and fixed by a different person than the one who fixed bug #AMQ-5066.  The fix consists of modifying slightly the same lines of the code in the exact files used to fix Bug #AMQ-5066. In fact, Bug #5092 could have been avoided altogether if the first developer provided a more comprehensive fix to #AMQ-5066 (a task that is easier said than done). These two bugs are not duplicates since, according to their description, they deal with different types of problems and yet they can be fixed by providing a similar patch.  In other words, the failures are different while the root causes (faults in the code) are more or less the same. 
From the bug handling perspective, if we can develop a way to detect such related bug reports during triaging then we can achieve considerable time saving in the way bug reports are processed, for example, by assigning them to the same developers. We also conjecture that detecting such related bugs can help with other tasks such as bug reproduction. We can  reuse the reproduction of an already fixed bug to reproduce an incoming and related bug.



\section{Research Contributions\label{sec:objective-thesis}}

In this section, we present our research contributions that are listed here and developed in more detail in the next subsections.

\begin{itemize}
	\item A bug reproduction technique based on a combination of crash traces and model checking.
    \item An aggregate bug  repository for  developers  and  Researchers
	\item An incremental approach for preventing clone insertion at commit time
	\item A new taxonomy of bugs based on the location of the corrections - an empirical Study
\end{itemize}

\subsection{A bug reproduction technique based on a combination of crash traces and model checking.}

In this work, we propose an approach, called JCHARMING (Java CrasH Automatic Reproduction by directed Model checkING) that uses a combination of crash traces and model checking to automatically reproduce bugs that caused field failures. Unlike existing techniques, JCHARMING does not require instrumentation of the code. It does not need access to the content of the heap either. Instead, JCHARMING uses a list of functions output when an uncaught exception in Java occurs (i.e., the crash trace) to guide a model checking engine to uncover the statements that caused the crash. 

\subsection{An aggregate bug  repository for  developers  and  Researchers}
We introduce BUMPER (BUg Metarepository for  dEvelopers  and  Researchers),  a  web-based  infrastructure
that  can  be  used  by  software  developers  and  researchers  to access  data  from  diverse  repositories  using  natural  language queries in a transparent manner, regardless of where the data was originally created and hosted. The  idea  behind  BUMPER  is  that  it  can  connect  to  any bug  tracking  and  version  control  systems  and  download  the data  into  a  single  database.  We  created  a  common  schema that represents data, stored in various bug tracking and version control systems. BUMPER uses a web-based interface to allow users to search the aggregated database by expressing queries through a single point of access. This way, users can focus on the analysis itself and not on the way the data is represented or located. BUMPER supports many features including: (1) the ability to use multiple bug tracking and control version systems, (2) the  ability  to  search  very  efficiently  large  data  repositories using both natural language and a specialized query language, (3)  the  mapping  between  the  bug  reports  and  the  fixes,  and (4)  the  ability  to  export  the  search  results  in  Json,  CSV  and XML formats.

\subsection{An incremental approach for preventing bug and clone insertion at commit time}
In this research, we present PRECINCT (PREventing Clones INsertion at Commit Time) that focuses on preventing the
insertion of clones at commit time, i.e., before they reach the central code repository. PRECINCT is an online clone
detection technique that relies on the use of pre-commit hooks capabilities of modern source code version control systems.
A pre-commit hook is a process that one can implement to receive the latest modification to the source code done by a given developer just before the code reaches the central repository. PRECINCT intercepts this modification and analyses its content to see whether a suspicious clone has been introduced
or not. A flag is raised if a code fragment is suspected to be a clone of an existing code segment. In fact, PRECINCT, itself, can be seen as a pre-commit hook that detects clones that might have been inserted in the latest changes with regard to the rest of the source code. This said, only a fraction of the
code is analysed, making PRECINCT efficient compared to leading clone detection techniques such as NICAD (Accurate Detection of Near-miss Intentional Clones) [9]. Moreover, the detected clones are presented using a classical ‘diff’ output that developers are familiar with. PRECINCT is also well
integrated with the workflow of the developers since it is used in conjunction with a source code version control systems such as Git.

\subsection{A new taxonomy of bugs based on the location of the correction - an empirical Study}

We investigate the relationship between bugs by examining their locations of the fixes. By a fix, we mean a modification (adding or deleting lines of code) to an exiting file that is used to solve the bug.We argue that bugs can be classified into four types:
A bug of Type 1 refers to a bug being fixed in one single location (i.e., one file), while Type 2 refers to bugs being fixed in more than one location.  Type 3 refers to multiple bugs that are fixed in the exact same location. Type 4 is an extension of Type 3, where multiple bugs are resolved by modifying the same set of locations. Note that Type 3 and Type 4 bugs are not duplicates, they may occur when different features of the system fail due to the same root causes (faults). We conjecture that knowing the proportions of each type of bugs in a system may provide insights into the quality of the system. Knowing, for example, that in a given system the proportion of Type 2 and 4 bugs is high may be an indication of poor system quality since many fixes are needed to address these bugs.  In addition, the existence of a high number of Types 3 and 4 bugs calls for techniques that can effectively find bug reports related to an incoming bug during triaging. This is similar to the many studies that exist on detection of duplicates (e.g., [10]–[12]), except that we are not looking for duplicates but for related bugs (bugs that are due to failures of different features of the system, caused by the same faults). 

\section{Outline\label{sec:outline}}

The remaining chapters of this proposal are:

\begin{itemize}
	\item Chapter \ref{chap:relwork} - {\it Background \& Related work}.
	In this chapter, we present the major studies related to our research field, namely, crash reproduction, aggregating bug repositories for mining purposes, and clone detection.
	\item Chapter \ref{chap:aggreating} - {\it Aggregating Version Control and Project Management Systems}. In this chapter we discuss the components of JCHARMING, the bug reproduction approach we propose. 
    \item Chapter \ref{chap:bumper} - {\it BUMPER: Bug Meta-repository For Developers & Researchers}. In this chapter, we discuss our framework and supporting tool for aggregating bug repositories into a uniform infrastructure. 
	\item Chapter \ref{chap:clone-detection-pragmatic} {\it An Incremental Approach for Preventing Clone Insertion at Commit Time} 	This chapter describes three approaches to prevent the insertion of clones at commit time.
	\item Chapter \ref{chap:taxonomy} {\it A bug classification approach based on the locations of the corrections - an empirical study}. In this chapter, we present an empirical study in which we classify bugs based on the locations of the corrections.

	\item Chapter \ref{chap:plan} {\it Remaining Work to Complete the
Thesis} presents  the remaining work and a publication plan.
\end{itemize}
